blueprint:
  domain: automation
  name: Send assist commands using Telegram
  author: TheFes
  source_url: https://github.com/TheFes/ha-blueprints/blob/main/alert/telegram_assist.yaml
  description: >
    ![Image](https://github.com/TheFes/ha-blueprints/blob/main/images/TheFesCasa_logo_bp_light.png?raw=true)

    # üí¨ Telegram Assist

    This blueprint creates an autation which processes all messages sent in a Telegram chat as voice commands.

    ## ‚ùìHow to use

    Provide the settings as described below.

    For more information on all settings, see the [documentation](<https://github.com/TheFes/ha-blueprints/blob/main/alert/telegram_assist.md>).

    ## ‚òï Coffee

    If you think I deserve a coffe, please feel free to buy me one (I might spend it on another beverage though).

    In case you decide to do so, thanks a lot!

    <a href="https://www.buymeacoffee.com/thefes" target="_blank">![Buy Me A Coffee](https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png)</a>


    Or you can do a small donation using PayPal.

    [![paypal](https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif)](https://www.paypal.com/paypalme/thefes)

    ```
  homeassistant:
    min_version: 2025.11.0
  input:
    telegram_event:
      name: Telegram event entity
      description:
        The event entity from the Telegram Bot integration which referencing the chat in which you want
        to give the commands.
      selector:
        entity:
          multiple: true
          filter:
            - integration: telegram_bot
              domain: event
    llm_entity:
      name: LLM conversation entity
      description:
        The conversation entity from your LLM to be used as fallback of the local.
        Set to `Home Assistant (conversation.home_assistant)` to use local handling only.
      selector:
        entity:
          multiple: false
          filter:
            - domain: conversation
    prefer_local:
      name: Prefer local
      description:
        Disable if you only want to use the LLM. In case no LLM entity is provided, this setting will not be used.
      selector:
        boolean:
      default: true
triggers:
  - trigger: state
    entity_id: !input telegram_event
    not_from: unavailable
conditions:
  - condition: state
    entity_id: !input telegram_event
    state: telegram_text
    attribute: event_type
variables:
  telegram_event: !input telegram_event
  prefer_local: !input prefer_local
  llm_entity: !input llm_entity
  mapping: >
    {% set config_entry_list = telegram_event | map('config_entry_id') | list %}
    {% set ns = namespace(mapping=[], chat=[]) %}
    {% for entry in config_entry_list %}
      {% for event in telegram_event if config_entry_id(event) == entry %}
        {% set ns.chat = ns.chat + [state_attr(event, 'chat_id')] %}
      {% endfor %}
      {% set ns.mapping = ns.mapping + [dict(entry=entry, event=ns.chat)] %}
      {% set ns.event = [] %}
    {% endfor %}
    {{ ns.mapping }}
actions:
  - alias: Use local handling first if set
    if: "{{ prefer_local or llm_entity is none }}"
    then:
      - action: conversation.process
        data:
          agent_id: conversation.home_assistant
          text: "{{ trigger.to_state.attributes.text }}"
          conversation_id: telegram_assist
        response_variable: response
  - if: >
      {{ 
        not prefer_local
        or
        (
          llm_entity != 'conversation.home_assistant'
          and response is defined
          and response.response.response_type == 'error'
        )
      }}
    then:
      - action: conversation.process
        data:
          text: "{{ trigger.to_state.attributes.text }}"
          conversation_id: telegram_assist
          agent_id: !input llm_entity
        response_variable: response
  - repeat:
      for_each: "{{ mapping }}"
      sequence:
        - action: telegram_bot.send_message
          data:
            config_entry_id: "{{ repeat.item.entry }}"
            target: "{{ repeat.item.chat }}"
            message: "{{ response.response.speech.plain.speech }}"
            message_tag: conversation_response
mode: parallel
